{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Replace the URL with your own IPwebcam shot.jpg IP:port\n",
    "url='http://192.168.31.149:8080/shot.jpg'\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Use urllib to get the image and convert into a cv2 usable format\n",
    "    imgResp=urllib.urlopen(url)\n",
    "    imgNp=np.array(bytearray(imgResp.read()),dtype=np.uint8)\n",
    "    img=cv2.imdecode(imgNp,-1)\n",
    "    \n",
    "\n",
    "    #cv2.rectangle(img, pt1=(100,100), pt2=(200,200), color=(0,255,0), thickness=10)\n",
    "    img = cv2.filter2D(img, -1, np.ones((3,3))*10)\n",
    "    \n",
    "    # put the image on screen\n",
    "    cv2.imshow('IPWebcam', img)\n",
    "    \n",
    "    #To give the processor some less stress\n",
    "#     time.sleep(1) \n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "full = cv2.imread('DATA/sammy.jpg')\n",
    "full = cv2.cvtColor(full, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "face = cv2.imread('DATA/target.png')\n",
    "face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR','cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "hiegh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "for n in itertools.count():\n",
    "    # Use urllib to get the image and convert into a cv2 usable format\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    res = cv2.matchTemplate(frame, face, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    y_face, x_face, deep= face.shape\n",
    "\n",
    "    minVal, maxVal, minLoc, maxLoc= cv2.minMaxLoc(res)\n",
    "    pt1_x, pt1_y =maxLoc\n",
    "    pt2_x, pt2_y =pt1_x+x_face, pt1_y+y_face \n",
    "\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    cv2.putText(frame, \"max: {}, min: {}\".format(maxVal,minVal),org=(0,10),fontFace =font,fontScale=1,color=(0,255,0))\n",
    "    \n",
    "    \n",
    "    if maxVal > 0.5:\n",
    "        cv2.imwrite('DATA/emoji/smile_{}.png'.format(n), frame[pt1_y:pt2_y,pt1_x:pt2_x])\n",
    "        cv2.rectangle(frame, pt1 =(pt1_x, pt1_y), pt2=(pt2_x, pt2_y),color=[0,255,0], thickness=5)\n",
    "        \n",
    "    \n",
    "    # put the image on screen\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    time.sleep(1/30)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "plt.subplot(121)\n",
    "plt.imshow(res)\n",
    "print(res.shape)\n",
    "print(face.shape)\n",
    "print(frame.shape)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(frame)        \n",
    "    \n",
    "    \n",
    "plt.show()    \n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СОЗДАТЬ НАБОР ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys, os\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def smooth(values, threshold = 5):\n",
    "    #x, y, w, h\n",
    "    if \"to_smooth\" not in globals():\n",
    "        global to_smooth\n",
    "        to_smooth = np.array([values])\n",
    "          \n",
    "    to_smooth = np.concatenate([to_smooth, [values]])  \n",
    "    \n",
    "    x = to_smooth[len(to_smooth)-threshold:len(to_smooth),  0].mean()\n",
    "    y = to_smooth[len(to_smooth)-threshold:len(to_smooth),  1].mean()\n",
    "    w = to_smooth[len(to_smooth)-threshold:len(to_smooth),  2].mean()\n",
    "    h = to_smooth[len(to_smooth)-threshold:len(to_smooth),  3].mean()\n",
    "\n",
    "    to_smooth = to_smooth[len(to_smooth)-threshold:len(to_smooth)]\n",
    "    return int(x), int(y), int(w), int(h)\n",
    "\n",
    "\n",
    "def rotateImage(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cap   = cv2.VideoCapture(0)\n",
    "font  = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# Get user supplied values\n",
    "cascPath = r\"E:\\GitHub\\udemy\\DATA\\haarcascades\"\n",
    "if not os.path.exists(cascPath):\n",
    "    cascPath = r\"D:\\GitHub\\udemy\\DATA\\haarcascades\"\n",
    "# Create the haar cascade\n",
    "\n",
    "eyeCascade = cv2.CascadeClassifier(os.path.join(cascPath, 'haarcascade_eye.xml'))\n",
    "faceCascade = cv2.CascadeClassifier(os.path.join(cascPath,'haarcascade_frontalface_default.xml'))\n",
    "\n",
    "path = r'DATA/emoji/idle/'\n",
    "count_files = len(os.listdir(path))\n",
    "\n",
    "for n in itertools.count():\n",
    "    ret, image = cap.read()\n",
    "    image = cv2.resize(image, (160,120))\n",
    "    # Read the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _weights = []\n",
    "    _rects   = []\n",
    "    _angles  = []\n",
    "    for angle in range(-45, 45, 5):\n",
    "        # Detect faces in the image\n",
    "        faces = faceCascade.detectMultiScale3(\n",
    "        rotateImage(gray, angle),\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=10,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE,\n",
    "        outputRejectLevels = True)\n",
    "\n",
    "        #neighbours = faces[1]\n",
    "        rects   = faces[0]\n",
    "        weights = faces[2]\n",
    "        if type(weights) == type(np.array([])):\n",
    "            max_weight = weights.max()\n",
    "            mask  = weights == max_weight\n",
    "            rects = rects[mask.reshape(-1)]\n",
    "            \n",
    "            _weights.append(max_weight)\n",
    "            _rects.append(rects)          \n",
    "            _angles.append(angle)\n",
    "            \n",
    "    if _weights:        \n",
    "        _weights = np.array(_weights)\n",
    "        _rects   = np.array(_rects)\n",
    "        _angles  = np.array(_angles)\n",
    "\n",
    "        max_weight  = _weights.max()\n",
    "        mask  = _weights == max_weight\n",
    "        rects = _rects[mask.reshape(-1)]\n",
    "        angle = _angles[mask.reshape(-1)]\n",
    "        # Draw a rectangle around the faces\n",
    "        for x, y, w, h in rects[0]:\n",
    "#             x, y, w, h = smooth([x, y, w, h], threshold = 5)\n",
    "            \n",
    "            lower_h = int((h+y)*1)\n",
    "        \n",
    "        \n",
    "            fullpath = os.path.join(path,'_{}.png'.format(n+count_files))\n",
    "            \n",
    "            \n",
    "            to_save = cv2.resize(image[y:lower_h,x:w+x], (32,32))\n",
    "            cv2.imwrite(fullpath, to_save)\n",
    "            cv2.putText(image, \"weight:{}, angle:{}\".format(max_weight.round(), angle),org=(0,10),fontFace =font,fontScale=0.5,color=(0,255,0))\n",
    "            cv2.rectangle(image, (x, y), (x+w, lower_h), (0, 255, 0), 2)\n",
    "\n",
    "    #         roi_gray  = gray[y:y+h, x:x+w]\n",
    "    #         roi_color = image[y:y+h, x:x+w]\n",
    "    #         eyes = eyeCascade.detectMultiScale(roi_gray)\n",
    "    #         for (ex,ey,ew,eh) in eyes:\n",
    "    #             cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    "\n",
    "    # put the image on screen\n",
    "    cv2.imshow('Webcam', image)\n",
    "    time.sleep(1/30)\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "        \n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СКОНВЕРТИРОВАТЬ ДАННЫЕ(фото) В NUMPY МАССИВ ДЛЯ ОБУЧЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = r\"E:\\GitHub\\udemy\\DATA\\emoji\"\n",
    "nb_classes = os.listdir(path)\n",
    "\n",
    "\n",
    "X= []\n",
    "y= []\n",
    "range(len(nb_classes))\n",
    "for n, dir, classes in zip(range(len(nb_classes)), nb_classes, np.eye(len(nb_classes),k=0)):\n",
    "    fullpath = os.path.join(path, dir)\n",
    "    print(fullpath)\n",
    "    for image_name in os.listdir(fullpath):\n",
    "        image_fullpath = os.path.join(fullpath, image_name)\n",
    "        \n",
    "        image = cv2.imread(image_fullpath)\n",
    "        \n",
    "        X.append(image)\n",
    "        y.append([n])\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБУЧИТЬ СЕТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5747 samples, validate on 639 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 1.0940 - acc: 0.3698 - val_loss: 1.0578 - val_acc: 0.4773\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.6724 - acc: 0.6715 - val_loss: 0.3734 - val_acc: 0.8576\n",
      "Epoch 3/5\n",
      " - 14s - loss: 0.3356 - acc: 0.8596 - val_loss: 0.1988 - val_acc: 0.9186\n",
      "Epoch 4/5\n",
      " - 14s - loss: 0.1715 - acc: 0.9382 - val_loss: 0.0897 - val_acc: 0.9718\n",
      "Epoch 5/5\n",
      " - 14s - loss: 0.1084 - acc: 0.9635 - val_loss: 0.0572 - val_acc: 0.9812\n",
      "Точность работы на тестовых данных: 97.93%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(111)\n",
    "\n",
    "# Загружаем данные\n",
    "# (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 3\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 5#25\n",
    "# Размер изображений\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))#softmax , sigmoid\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=2)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ИСПОЛЬЗОВАТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys, os\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "from math import factorial\n",
    "\n",
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "        \n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')\n",
    "\n",
    "\n",
    "def value_to_buffer(value, buffer_name = '', threshold = 5):\n",
    "    if buffer_name not in globals():\n",
    "        globals()[buffer_name] = []\n",
    "          \n",
    "    globals()[buffer_name].append(value) \n",
    "    size = len(globals()[buffer_name])\n",
    "    \n",
    "    if size > threshold:\n",
    "        globals()[buffer_name] = globals()[buffer_name][size-threshold:size]\n",
    "        \n",
    "\n",
    "def rotateImage(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_weights(weights, rotate, path):\n",
    "    fullpath = os.path.join(path, \"weights.txt\")\n",
    "    with open(fullpath, 'w') as f:\n",
    "        f.write(\"[{}, {}]\".format(weights, rotate))\n",
    "\n",
    "        \n",
    "        \n",
    "CIFAR10_LABELS_LIST = [\n",
    "    '1 - idle', \n",
    "    '2 - jaw_open',\n",
    "    '3 - smile',]\n",
    "\n",
    "CIFAR10_LABELS_LIST = np.array(CIFAR10_LABELS_LIST)\n",
    "\n",
    "\n",
    "cap   = cv2.VideoCapture(0)\n",
    "font  = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# Get user supplied values\n",
    "cascPath = r\"E:\\GitHub\\udemy\\DATA\\haarcascades\"\n",
    "if not os.path.exists(cascPath):\n",
    "    cascPath = r\"D:\\GitHub\\udemy\\DATA\\haarcascades\"\n",
    "# Create the haar cascade\n",
    "\n",
    "eyeCascade = cv2.CascadeClassifier(os.path.join(cascPath, 'haarcascade_eye.xml'))\n",
    "faceCascade = cv2.CascadeClassifier(os.path.join(cascPath,'haarcascade_frontalface_default.xml'))\n",
    "\n",
    "\n",
    "\n",
    "for n in itertools.count():\n",
    "    ret, image = cap.read()\n",
    "    image = cv2.resize(image, (160,120))\n",
    "    # Read the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _weights = []\n",
    "    _rects   = []\n",
    "    _angles  = []\n",
    "    for angle in range(-35, 35, 5):\n",
    "        # Detect faces in the image\n",
    "        faces = faceCascade.detectMultiScale3(\n",
    "        rotateImage(gray, angle),\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=10,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE,\n",
    "        outputRejectLevels = True)\n",
    "\n",
    "        #neighbours = faces[1]\n",
    "        rects   = faces[0]\n",
    "        weights = faces[2]\n",
    "        if type(weights) == type(np.array([])):\n",
    "            max_weight = weights.max()\n",
    "            mask  = weights == max_weight\n",
    "            rects = rects[mask.reshape(-1)]\n",
    "            \n",
    "            _weights.append(max_weight)\n",
    "            _rects.append(rects)          \n",
    "            _angles.append(angle)\n",
    "            \n",
    "    if _weights:        \n",
    "        _weights = np.array(_weights)\n",
    "        _rects   = np.array(_rects)\n",
    "        _angles  = np.array(_angles)\n",
    "\n",
    "        max_weight  = _weights.max()\n",
    "        mask  = _weights == max_weight\n",
    "        rects = _rects[mask.reshape(-1)]\n",
    "        angle = _angles[mask.reshape(-1)]\n",
    "        # Draw a rectangle around the faces\n",
    "        for x, y, w, h in rects[0]:  \n",
    "            lower_h = int((h+y)*1)\n",
    "            \n",
    "            to_match= cv2.resize(image[y:lower_h,x:w+x], (32,32)) /255\n",
    "            weights = model.predict(np.array([to_match]))[0]\n",
    "            mask    = weights == weights.max()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            value_to_buffer(float(weights[0]), buffer_name = '_idle',    threshold = 6)\n",
    "            value_to_buffer(float(weights[1]), buffer_name = '_jaw_open',threshold = 6)\n",
    "            value_to_buffer(float(weights[2]), buffer_name = '_smile',   threshold = 6)\n",
    "            value_to_buffer(float(angle  [0]), buffer_name = '_rotateZ', threshold = 6)\n",
    "            \n",
    "            if len(_idle) >= 6:\n",
    "                idle     = savitzky_golay(np.array(_idle), window_size = 5, order = 1, deriv=0, rate=1)    [-2]\n",
    "                jaw_open = savitzky_golay(np.array(_jaw_open), window_size = 5, order = 1, deriv=0, rate=1)[-2]\n",
    "                smile    = savitzky_golay(np.array(_smile), window_size = 5, order = 1, deriv=0, rate=1)   [-2]\n",
    "                rotateZ  = savitzky_golay(np.array(_rotateZ), window_size = 5, order = 1, deriv=0, rate=1) [-2]\n",
    "\n",
    "            \n",
    "                write_weights([idle,\n",
    "                              jaw_open,\n",
    "                              smile], \n",
    "                              rotateZ, path = r'E:\\GitHub\\udemy')###\n",
    "\n",
    "                cv2.putText(img      = image, \n",
    "                            text     = \"{},{}\".format(CIFAR10_LABELS_LIST[mask], weights.round(3)),\n",
    "                            org      = (0,10),\n",
    "                            fontFace = font,\n",
    "                            fontScale= 0.5,\n",
    "                            color    = (0,255,0))\n",
    "                \n",
    "                \n",
    "            cv2.rectangle(image, (x, y), (x+w, lower_h), (0, 255, 0), 2)\n",
    "\n",
    "        #         roi_gray  = gray[y:y+h, x:x+w]\n",
    "    #         roi_color = image[y:y+h, x:x+w]\n",
    "    #         eyes = eyeCascade.detectMultiScale(roi_gray)\n",
    "    #         for (ex,ey,ew,eh) in eyes:\n",
    "    #             cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    "\n",
    "    # put the image on screen\n",
    "    cv2.imshow('Webcam', image)\n",
    "    time.sleep(1/30)\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "del _idle\n",
    "del _jaw_open\n",
    "del _smile\n",
    "del _rotateZ\n",
    "\n",
    "\n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
